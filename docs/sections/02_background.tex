\section{Landasan Teori}
\label{sec:background}

\subsection{Citra Digital}
Citra didefinisikan sebagai fungsi intensitas cahaya dwimatra $f(x, y)$, di mana $x$ dan $y$ merupakan koordinat spasial dan nilai $f$ di titik tersebut menyatakan intensitas atau tingkat keabuan (\textit{gray level}) dari citra. Agar citra dapat diolah oleh komputer digital, citra kontinu harus dikonversi menjadi bentuk digital melalui dua proses utama: pencuplikan (\textit{sampling}) dan kuantisasi (\textit{quantization}). \textit{Sampling} mendigitasi koordinat spasial $(x,y)$, sedangkan \textit{quantization} mendigitasi nilai amplitudo $f(x,y)$ ke dalam nilai-nilai diskrit \cite{Munir2025_Part1}.

Dalam representasi digital, citra dinyatakan sebagai matriks berukuran $M \times N$ dengan jumlah tingkat keabuan $L = 2^k$, di mana $k$ adalah kedalaman bit. Elemen-elemen diskrit dalam matriks ini disebut elemen gambar atau \textit{pixels}. Setiap \textit{pixel} memiliki lokasi spesifik dan nilai intensitas yang merepresentasikan informasi visual pada titik tersebut. Kualitas representasi citra sangat bergantung pada resolusi spasial ($N, M$) dan resolusi kecerahan ($k$) yang digunakan \cite{Munir2025_Part2}.

\subsection{Pemrosesan Citra Digital}
Pemrosesan Citra Digital (\textit{Digital Image Processing}) adalah disiplin ilmu yang mempelajari teknik-teknik pengolahan citra menggunakan algoritma komputer. Tujuan utamanya meliputi perbaikan kualitas citra agar lebih mudah diinterpretasikan oleh manusia (\textit{image enhancement}), pemulihan citra dari degradasi atau gangguan (\textit{image restoration}), serta ekstraksi fitur untuk keperluan analisis komputasi lebih lanjut. Operasi pemrosesan dapat dilakukan dalam domain spasial (langsung pada \textit{pixels}) maupun domain frekuensi \cite{Munir2025_Part1}.

Salah satu teknik \textit{enhancement} yang krusial adalah perbaikan kontras (\textit{contrast stretching}). Teknik ini bertujuan untuk memperluas jangkauan dinamis tingkat keabuan citra sehingga detail yang sebelumnya tersembunyi menjadi lebih terlihat \cite{Munir2025_Enhancement}. Pada data dengan distribusi intensitas yang ekstrem, normalisasi berbasis persentil (\textit{percentile-based normalization}) sering digunakan untuk mengabaikan \textit{outliers} dan memetakan rentang intensitas yang relevan ke dalam jangkauan standar visual ($0-255$).

Secara konseptual, bidang ini berbeda dengan Grafika Komputer dan \textit{Computer Vision}. Grafika Komputer bertujuan mensintesis citra dari deskripsi data geometris primitif. Sebaliknya, Pemrosesan Citra berfokus pada transformasi citra-ke-citra (misalnya, dari citra kabur menjadi tajam). Sementara itu, Pengenalan Pola dan \textit{Computer Vision} berada pada tingkat yang lebih tinggi, di mana tujuannya adalah melakukan interpretasi semantik dan pemahaman terhadap objek yang terkandung dalam citra hasil pemrosesan tersebut \cite{Munir2025_Part1}.

\subsection{\textit{Seismic Reflection Data}}
\textit{Seismic reflection surveying} adalah metode utama untuk memperoleh citra struktur bawah permukaan bumi, baik di darat (\textit{on-shore}) maupun di laut (\textit{off-shore}). Prinsip dasarnya bergantung pada kontras impedansi akustik antar lapisan batuan. Gelombang akustik yang dikirimkan ke dalam bumi akan dipantulkan kembali ke permukaan ketika bertemu dengan batas lapisan yang memiliki perbedaan impedansi, yang disebut sebagai \textit{reflectors}. Tujuan utamanya adalah mengekstraksi informasi struktural bawah permukaan dari rekaman waktu tempuh gelombang tersebut \cite{IntroReflectionSeismics_Chapter5}.

Pemrosesan data seismik mentah melibatkan tahapan yang kompleks untuk menghilangkan \textit{noise} dan menempatkan reflektor pada posisi yang benar. Tahapan standar meliputi pengurutan \textit{Common Mid-Point} (CMP), analisis kecepatan (\textit{velocity analysis}), dan koreksi \textit{Normal Move-Out} (NMO) untuk mengoreksi efek geometri akuisisi. Proses \textit{stacking} kemudian dilakukan untuk meningkatkan rasio sinyal-terhadap-derau. Langkah krusial terakhir adalah migrasi (\textit{migration}), yang menggunakan model kecepatan gelombang untuk memfokuskan energi difraksi dan mengembalikan struktur miring ke posisi spasial yang sebenarnya. Citra akhir yang dihasilkan merepresentasikan penampang bawah permukaan dalam domain waktu atau kedalaman \cite{IntroReflectionSeismics_Chapter5}.

Data ini sering kali memiliki karakteristik visual yang menantang, seperti \textit{low signal-to-noise ratio} dan diskontinuitas struktural. Dalam studi kasus deteksi bahaya geologi di margin kontinental Greenland, data seismik 3D digunakan untuk memetakan risiko pengeboran. Struktur-struktur bawah permukaan seperti kantong gas (\textit{gas pockets}), zona kekacauan batuan (\textit{chaotic zones}), dan patahan (\textit{faults}) dianggap sebagai "anomali" atau bahaya geologi (\textit{geohazards}) yang signifikan. Secara visual, anomali ini sering kali muncul sebagai diskontinuitas mendadak pada reflektor yang seharusnya kontinu, atau sebagai area dengan tekstur seismik yang berbeda secara signifikan dari lingkungan sekitarnya \cite{ScientificDrilling2020}. Interpretasi visual yang akurat terhadap fitur-fitur ini sangat penting untuk mitigasi risiko dalam eksplorasi dan pengeboran.

\subsection{\textit{Deep Learning} pada Data Seismik}
Penerapan \textit{Deep Learning} (DL) dalam interpretasi seismik telah menjadi topik penelitian aktif, khususnya untuk tugas mendasar seperti deteksi patahan (\textit{fault detection}). Patahan merupakan faktor kontrol utama dalam delineasi reservoir dan transportasi fluida, serta dapat menjadi bahaya pengeboran. Interpretasi manual sangat bergantung pada pengalaman ahli dan sulit memenuhi kebutuhan efisiensi modern \cite{RemoteSensing2023}.

Secara tradisional, metode berbasis \textit{Convolutional Neural Networks} (CNNs) 3D digunakan karena kemampuannya mengekstraksi informasi spasial penuh dari volume seismik. Namun, metode 3D membutuhkan sumber daya komputasi yang sangat besar dan sering kali terkendala oleh keterbatasan perangkat keras. Di sisi lain, metode CNN 2D lebih efisien secara komputasi (mengolah per \textit{slice}) tetapi cenderung kehilangan korelasi spasial antar \textit{slice}. 

Tantangan teknis utama dalam penerapan CNN 2D pada citra seismik adalah resolusi citra yang sangat besar (mencapai ribuan piksel), yang jauh melebihi ukuran masukan standar arsitektur jaringan saraf. Oleh karena itu, metode pembagian citra menjadi bagian-bagian kecil (\textit{patch-based processing} atau \textit{tiling}) sering diterapkan untuk memungkinkan pemrosesan yang efisien tanpa kehilangan resolusi asli \cite{RemoteSensing2023}.

\subsection{YOLO (\textit{You Only Look Once})}
YOLO merupakan pendekatan \textit{object detection} yang membingkai masalah deteksi sebagai masalah regresi tunggal (\textit{single regression problem}), bukan sebagai masalah klasifikasi pada ribuan \textit{region proposal} terpisah (seperti R-CNN). Dalam arsitektur YOLO, citra masukan dibagi menjadi kisi-kisi (\textit{grid}) berukuran $S \times S$. Jika titik tengah suatu objek jatuh ke dalam sel kisi tertentu, sel tersebut bertanggung jawab untuk mendeteksi objek tersebut \cite{YOLO_v1}.

Setiap sel kisi memprediksi $B$ \textit{bounding boxes} beserta skor kepercayaan (\textit{confidence scores}) untuk kotak-kotak tersebut, serta probabilitas kelas kondisional ($C$). Skor kepercayaan didefinisikan sebagai $Pr(Object) \times IOU_{pred}^{truth}$, yang mencerminkan seberapa yakin model bahwa kotak tersebut berisi objek dan seberapa akurat kotak yang diprediksi tersebut. Seluruh proses deteksi dilakukan dalam satu evaluasi jaringan saraf tunggal (\textit{unified architecture}), yang memungkinkan optimalisasi \textit{ end-to-end} dan kecepatan inferensi \textit{real-time}, sekaligus mengurangi kesalahan \textit{false positive} pada latar belakang dibandingkan metode tradisional \cite{YOLO_v1}.

Implementasi modern YOLO sering kali memanfaatkan teknik \textit{Transfer Learning}, di mana model diinisialisasi menggunakan bobot hasil pelatihan pada dataset berskala besar (seperti COCO Dataset). Pendekatan ini memungkinkan model untuk "mentransfer" kemampuan ekstraksi fitur dasar (seperti tepi dan tekstur) ke domain baru (seperti seismik) dengan lebih cepat dan akurat, meskipun jumlah data pelatihan pada domain target relatif terbatas.

\subsection{Metrik Evaluasi Deteksi Objek}
Evaluasi kinerja model deteksi objek menggunakan metrik standar yang berbeda dengan klasifikasi citra biasa \cite{Henderson2016, Rezatofighi2019}. Metrik utama yang digunakan meliputi \textit{Intersection over Union} (IoU), \textit{Precision}, \textit{Recall}, dan \textit{Mean Average Precision} (mAP).

\subsubsection{Intersection over Union (IoU)}
IoU mengukur tumpang tindih antara kotak prediksi ($B_p$) dan kotak \textit{ground truth} ($B_{gt}$). Nilai IoU didefinisikan sebagai rasio luas irisan terhadap luas gabungan kedua kotak tersebut:
\begin{equation}
IoU = \frac{Area(B_p \cap B_{gt})}{Area(B_p \cup B_{gt})}
\end{equation}
Nilai IoU berkisar antara 0 hingga 1. Sebuah prediksi dianggap benar (\textit{True Positive}) jika nilai IoU-nya melebihi ambang batas tertentu (biasanya 0.5).

\subsubsection{Precision dan Recall}
\textit{Precision} mengukur seberapa akurat deteksi positif yang dilakukan oleh model, sedangkan \textit{Recall} mengukur seberapa baik model menemukan seluruh objek positif yang ada dalam dataset.
\begin{equation}
Precision = \frac{TP}{TP + FP}
\end{equation}
\begin{equation}
Recall = \frac{TP}{TP + FN}
\end{equation}
Dimana $TP$ adalah \textit{True Positive}, $FP$ adalah \textit{False Positive}, dan $FN$ adalah \textit{False Negative}.

\subsubsection{Mean Average Precision (mAP)}
mAP adalah rata-rata dari \textit{Average Precision} (AP) untuk setiap kelas. AP sendiri dihitung dengan mencari luas daerah di bawah kurva \textit{Precision-Recall}. Metrik mAP@0.5 menghitung mAP dengan ambang batas IoU sebesar 0.5, sedangkan mAP@0.5:0.95 menghitung rata-rata mAP pada berbagai ambang batas IoU (dari 0.5 hingga 0.95 dengan interval 0.05). Metrik ini memberikan gambaran performa model yang lebih komprehensif, mencakup akurasi lokasi dan klasifikasi.
