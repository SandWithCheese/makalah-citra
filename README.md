# Seismic Subsurface Hazard Detection with YOLO

**Pemrosesan Citra Digital - Final Project**  
_Deep Learning-Based Object Detection for Seismic Image Analysis_

---

## üìã Project Overview

This project applies **YOLO (You Only Look Once)** object detection to identify subsurface hazards in seismic imagery. The goal is to detect visual patterns consistent with geological anomalies such as:

- **Fault zones** - Structural discontinuities
- **Gas chimneys** - Vertical migration pathways
- **Subsurface voids** - Cavities or karst features
- **Weak layers** - Potentially unstable strata

> [!IMPORTANT]
> This is a **pattern-based detection system**, not definitive geological interpretation. All detections are relative to human-labeled training data and should be validated by domain experts.

---

## üóÇÔ∏è Project Structure

```
makalah-citra/
‚îú‚îÄ data/                    
‚îÇ  ‚îú‚îÄ raw/                 # Raw input seismic images (for tiling)
‚îÇ  ‚îú‚îÄ processed/           # Tiled images ready for annotation
‚îÇ  ‚îú‚îÄ train/               # YOLO training data (generated by train script)
‚îÇ  ‚îú‚îÄ val/                 # YOLO validation data (generated by train script)
‚îÇ  ‚îî‚îÄ README.md
‚îÇ
‚îú‚îÄ preprocessing/           # Seismic image preprocessing
‚îÇ  ‚îú‚îÄ seismic_tiler.py     # Tile generator (fixed input/output)
‚îÇ  ‚îî‚îÄ README.md
‚îÇ
‚îú‚îÄ runs/                    # YOLO training outputs
‚îÇ  ‚îî‚îÄ detect/train/        # Metrics, curves, confusion matrix
‚îÇ
‚îú‚îÄ docs/                    # IEEE LaTeX documentation (academic paper)
‚îú‚îÄ src/                     # Source code and helper scripts
‚îÇ  ‚îú‚îÄ train_yolo.py        # Main training script
‚îÇ  ‚îî‚îÄ run_train.sh         # Helper script for CUDA environment
‚îÇ
‚îú‚îÄ results/                 # Experimental results and visualizations
‚îú‚îÄ data.yaml                # YOLO dataset configuration (auto-generated)
‚îú‚îÄ requirements.txt         # Python dependencies
‚îî‚îÄ README.md                # This file
```

---

## üöÄ Quick Start

### 1. Environment Setup (Local)

This project is designed for **local execution** on Linux with an NVIDIA GPU.

```bash
# 1. Create and activate a virtual environment
python3 -m venv venv
source venv/bin/activate

# 2. Install PyTorch and torchvision (CUDA 13.0)
# Note: Verified for NVIDIA GPUs with recent drivers
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu130

# 3. Install other dependencies
pip install -r requirements.txt

# 4. Verify GPU availability
nvidia-smi
```

### 2. Dataset Preparation

#### Step A: Tiling Raw Images
Place your raw seismic image files (e.g., `.tif`, `.png`) in `data/raw/`.

```bash
# Run the tiler (automatically processes data/raw -> data/processed)
python preprocessing/seismic_tiler.py --tile 640 --overlap 0.2
```

#### Step B: Labeling with Label Studio
We use **Label Studio** for annotating the tiled images.

1.  **Install & Start:**
    ```bash
    pip install label-studio
    label-studio start
    ```
2.  **Create Project:**
    -   Name: "Seismic Hazard Detection"
    -   Setup: "Object Detection with Bounding Boxes"
3.  **Import Data:**
    -   Upload images from `data/processed/<image_name>/`.
4.  **Labeling:**
    -   Create labels: `fault`, `gas_chimney`, `void`, `weak_layer`.
    -   Draw bounding boxes around anomalies.
5.  **Export:**
    -   Export format: **YOLO**.
    -   Download usage: Unzip the export. It will contain `images/`, `labels/`, and `classes.txt`.
    -   **Important:** Rename/Move the folder or zip it as `data.zip` for the training script.

### 3. Training

Use the helper script `run_train.sh` to handle CUDA library paths automatically.

```bash
# Ensure you have your annotated dataset zip
# Default expects 'data.zip' in the current directory
# or specify with --data_zip path/to/data.zip

cd src
./run_train.sh \
  --data_zip ../data.zip \
  --model yolo11s.pt \
  --epochs 100 \
  --imgsz 640 \
  --batch 16
```

**Training artifacts saved to:** `runs/detect/train/`

### 4. Evaluation

```bash
# Validate on test set using the best model
yolo detect val \
  model=runs/detect/train/weights/best.pt \
  data=data.yaml
```

### 5. Inference

```bash
# Run predictions on new images
yolo detect predict \
  model=runs/detect/train/weights/best.pt \
  source=data/processed/new_image_folder/ \
  save=True
```

---

## üìä Key Features

### Domain-Specific Preprocessing

1.  **Percentile Clipping** (2th-98th percentiles)
    -   Removes extreme outliers in seismic amplitude
    -   Preserves geological features while enhancing contrast
2.  **Overlap Tiling** (20% default)
    -   Prevents anomaly truncation at tile boundaries
3.  **Blank Tile Filtering**
    -   Removes uninformative regions (low variance)

See [`preprocessing/README.md`](preprocessing/README.md) for details.

---

## üìà Evaluation Metrics

| Metric | Description |
|--------|-------------|
| **Precision** | % of detections that are true positives |
| **Recall** | % of actual hazards detected |
| **mAP@0.5** | Mean Average Precision at IoU=0.5 |
| **mAP@0.5:0.95** | mAP averaged over IoU thresholds |

---

## üî¨ Methodology

### Why YOLO for Seismic Hazard Detection?

1.  **Real-time capability** - Fast inference suitable for large-scale surveys
2.  **End-to-end learning** - Learns spatial patterns without manual feature engineering
3.  **Localization** - Provides bounding boxes for spatial reference

### Limitations

-   **Not semantic segmentation** - Bounding boxes may overestimate anomaly extent
-   **Annotation-dependent** - Model learns human labeling patterns, not ground truth geology
-   **Context limitations** - Tiling may miss large-scale geological structures

---

## üõ†Ô∏è Technical Stack

-   **Deep Learning Framework**: [Ultralytics YOLO](https://github.com/ultralytics/ultralytics) (v8/v11/v12 support)
-   **Image Processing**: NumPy, Pillow
-   **Programming Language**: Python 3.8+
-   **Hardware**: NVIDIA GPU recommended (CUDA 13+)

---

## üìñ References

-   [Ultralytics YOLO Documentation](https://docs.ultralytics.com/)
-   [Label Studio](https://labelstud.io/)
-   IEEE Conference Paper Template (see `docs/`)

---

## üîó Quick Links

-   [Dataset Structure](data/README.md)
-   [Preprocessing Pipeline](preprocessing/README.md)
-   [Training Documentation](src/README.md)
-   [Academic Paper (docs/)](docs/)
-   [Agent Rules](.agent/rules/agent-rule.md)

